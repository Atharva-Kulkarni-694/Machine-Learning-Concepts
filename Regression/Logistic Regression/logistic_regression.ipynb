{"nbformat": 4, "nbformat_minor": 5, "metadata": {}, "cells": [{"id": "ad47af40", "cell_type": "markdown", "source": "# 1. Importing Required Libraries", "metadata": {}}, {"id": "7f69335c", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    accuracy_score, confusion_matrix, \n    classification_report, roc_auc_score, roc_curve\n)", "outputs": []}, {"id": "5bc27dbe", "cell_type": "markdown", "source": "\ud83d\udcab We import all the necessary libraries for performing **Logistic Regression analysis**.  \nThis includes tools for data handling, visualization, scaling, model building, and evaluation.", "metadata": {}}, {"id": "95dfdc61", "cell_type": "markdown", "source": "# 2. Loading and Preparing the Data", "metadata": {}}, {"id": "267a5582", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "# Load data\ndf = pd.read_csv(\"your_data.csv\")\n\n# Replace with your column names\nfeature_columns = [\"feature1\", \"feature2\", \"feature3\"]   # Multiple features work well\ntarget_column = \"target_column\"  # Should be categorical/binary\n\nX = df[feature_columns]\ny = df[target_column]\n\n# Check target variable type\nunique_classes = y.nunique()\nprint(f\"Target variable has {unique_classes} unique classes: {y.unique()}\")", "outputs": []}, {"id": "663152a4", "cell_type": "markdown", "source": "\ud83d\udcab We load our dataset using `pd.read_csv()`.  \nWe separate **features (X)** and **target (y)**.  \nWe also check if the target variable is **binary** or **multiclass**.", "metadata": {}}, {"id": "b73e0d89", "cell_type": "markdown", "source": "# 3. Splitting Data into Training and Testing Sets", "metadata": {}}, {"id": "05259567", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "# Split data\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)", "outputs": []}, {"id": "2f9b8f80", "cell_type": "markdown", "source": "\ud83d\udcab We split the dataset into **training (80%)** and **testing (20%)** sets,  \nwhile keeping the target class distribution balanced (`stratify=y`).", "metadata": {}}, {"id": "332db6b9", "cell_type": "markdown", "source": "# 4. Feature Scaling", "metadata": {}}, {"id": "df8f87e3", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "# Scale features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)", "outputs": []}, {"id": "5cc39b67", "cell_type": "markdown", "source": "\ud83d\udcab We use **StandardScaler** to normalize features,  \nensuring better performance of Logistic Regression.", "metadata": {}}, {"id": "d2f0945b", "cell_type": "markdown", "source": "# 5. Training the Logistic Regression Model", "metadata": {}}, {"id": "120a753f", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "# Train model\nmodel = LogisticRegression(max_iter=1000, random_state=42)\nmodel.fit(X_train_scaled, y_train)", "outputs": []}, {"id": "f5ec796e", "cell_type": "markdown", "source": "\ud83d\udcab We train a **Logistic Regression model** on the scaled training data.", "metadata": {}}, {"id": "bf8869d5", "cell_type": "markdown", "source": "# 6. Making Predictions", "metadata": {}}, {"id": "c66cad01", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred_proba = model.predict_proba(X_test_scaled)", "outputs": []}, {"id": "272f53bf", "cell_type": "markdown", "source": "\ud83d\udcab The model predicts both **class labels** (`y_pred`)  \nand **class probabilities** (`y_pred_proba`).", "metadata": {}}, {"id": "3d808346", "cell_type": "markdown", "source": "# 7. Evaluating the Model", "metadata": {}}, {"id": "5f9c5ca1", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "# Calculate metrics\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\n\nprint(\"=\"*50)\nprint(\"LOGISTIC REGRESSION RESULTS\")\nprint(\"=\"*50)\nprint(f\"Features: {feature_columns}\")\nprint(f\"Target: {target_column}\")\nprint(f\"Number of classes: {unique_classes}\")\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"\\nConfusion Matrix:\\n{conf_matrix}\")\nprint(f\"\\nClassification Report:\\n{classification_report(y_test, y_pred)}\")", "outputs": []}, {"id": "4b9cde12", "cell_type": "markdown", "source": "\ud83d\udcab We calculate key evaluation metrics:  \n- **Accuracy**  \n- **Confusion Matrix**  \n- **Classification Report (Precision, Recall, F1-score)**", "metadata": {}}, {"id": "9b733a73", "cell_type": "markdown", "source": "# 8. Visualizing the Confusion Matrix", "metadata": {}}, {"id": "5a9c9695", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "plt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n            xticklabels=model.classes_, yticklabels=model.classes_)\nplt.title('Confusion Matrix')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()", "outputs": []}, {"id": "fca56cc5", "cell_type": "markdown", "source": "\ud83d\udcab A **heatmap** of the confusion matrix provides  \na clear picture of how well the model classified each class.", "metadata": {}}, {"id": "a3549ae2", "cell_type": "markdown", "source": "# 9. Plotting the ROC Curve (for Binary Classification)", "metadata": {}}, {"id": "c6d3ea0f", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "if unique_classes == 2:\n    fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])\n    roc_auc = roc_auc_score(y_test, y_pred_proba[:, 1])\n\n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, \n             label=f'ROC curve (AUC = {roc_auc:.2f})')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend(loc=\"lower right\")\n    plt.grid(True)\n    plt.show()", "outputs": []}, {"id": "b8bab219", "cell_type": "markdown", "source": "\ud83d\udcab The **ROC Curve** evaluates the model\u2019s ability  \nto distinguish between two classes.  \nThe **AUC score** summarizes this performance.", "metadata": {}}]}